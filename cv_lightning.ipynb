{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850a397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from lightning import Trainer, LightningModule, LightningDataModule\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, RichProgressBar\n",
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from clearml import Task\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116106e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cf2e0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 42, 'batch_size': 64, 'lr': 0.0002, 'num_epochs': 10, 'noise_dim': 100, 'gen_dict': {'kernel_size': 4, 'stride': 2, 'padding': 1}, 'disc_dict': {'kernel_size': 4, 'stride': 2, 'padding': 1}}\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class CFG:\n",
    "    seed: int = 42\n",
    "    batch_size: int = 64\n",
    "    lr: float = 0.0002\n",
    "    num_epochs: int = 10\n",
    "    noise_dim: int = 100\n",
    "    # device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    gen_dict: dict = field(default_factory=lambda: {\n",
    "        'kernel_size': 4,\n",
    "        'stride': 2,\n",
    "        'padding': 1,\n",
    "    })\n",
    "    disc_dict: dict = field(default_factory=lambda: {\n",
    "        'kernel_size': 4,\n",
    "        'stride': 2,\n",
    "        'padding': 1,\n",
    "    })\n",
    "    \n",
    "cfg = CFG()\n",
    "cfg_dict = asdict(cfg)\n",
    "print(cfg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55b0e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f70ebe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = Task.init(project_name='GAN', task_name='GAN Training', task_type=Task.TaskTypes.training)\n",
    "# #task.add_tags([])\n",
    "# task.connect(cfg_dict) # Добавление конфигурации в ClearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "072eeb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(LightningDataModule):\n",
    "    def __init__(self, batch_size=64):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        datasets.MNIST(root='./data', train=True, download=True)\n",
    "        datasets.MNIST(root='./data', train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.mnist_train = datasets.MNIST(root='./data', train=True, transform=self.transform)\n",
    "        self.mnist_test = datasets.MNIST(root='./data', train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size, shuffle=True, num_workers=20)\n",
    "\n",
    "    # def val_dataloader(self):\n",
    "    #     return DataLoader(self.mnist_test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbbb76f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = MNISTDataModule(batch_size=cfg.batch_size)\n",
    "module.prepare_data()\n",
    "module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "934dd62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim=100, *args, **kwargs):\n",
    "        super(Generator, self).__init__()\n",
    "        kernel_size = kwargs.get('kernel_size', 4)\n",
    "        stride = kwargs.get('stride', 2)\n",
    "        padding = kwargs.get('padding', 1)\n",
    "        self.main = nn.Sequential(\n",
    "            # Вход: вектор шума размера noise_dim\n",
    "            nn.Linear(noise_dim, 256 * 7 * 7),\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(1, (256, 7, 7)),\n",
    "            # Состояние: (256, 7, 7)\n",
    "            nn.ConvTranspose2d(\n",
    "                256, 128, kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n",
    "            ),  # -> (128, 14, 14)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(\n",
    "                128, 1, kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n",
    "            ),  # -> (1, 28, 28)\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "        \n",
    "        \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Discriminator, self).__init__()\n",
    "        kernel_size = kwargs.get('kernel_size', 4)\n",
    "        stride = kwargs.get('stride', 2)\n",
    "        padding = kwargs.get('padding', 1)\n",
    "        self.main = nn.Sequential(\n",
    "            # Вход: изображение (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                1, 64, kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n",
    "            ),  # -> (64, 14, 14)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(\n",
    "                64, 128, kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n",
    "            ),  # -> (128, 7, 7)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 7 * 7, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11a50fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_MNIST_Model(LightningModule):\n",
    "    def __init__(self, noise_dim=100, gen_dict=None, disc_dict=None):\n",
    "        super().__init__()\n",
    "        self.generator = Generator(noise_dim=noise_dim, **(gen_dict or {})).to(device)\n",
    "        self.discriminator = Discriminator( **(disc_dict or {})).to(device)\n",
    "        self.criterion = nn.BCELoss()\n",
    "        \n",
    "        self.noise_dim = noise_dim\n",
    "        self.real_label = 1.0\n",
    "        self.fake_label = 0.0\n",
    "        self.automatic_optimization = False  # Отключаем автоматическое управление оптимизацией\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.generator(input)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # import pdb; pdb.set_trace()\n",
    "        opt_g, opt_d = self.optimizers()\n",
    "        real_images, _ = batch\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "        noise = torch.randn(batch_size, self.noise_dim, device=device)\n",
    "        label = torch.full((batch_size,), self.real_label, device=device)\n",
    "\n",
    "        # Обучение генератора\n",
    "        opt_g.zero_grad()\n",
    "        fake_images = self(noise)\n",
    "        output = self.discriminator(fake_images).view(-1)\n",
    "        errG = self.criterion(output, label)\n",
    "        D_G_z2 = output.mean().item()\n",
    "        #errG.backward()\n",
    "        self.manual_backward(errG)\n",
    "        opt_g.step()\n",
    "        #optimizer_g.step()\n",
    "        #return errG\n",
    "\n",
    "        # Обучение дискриминатора\n",
    "        opt_d.zero_grad()\n",
    "        output = self.discriminator(real_images).view(-1)\n",
    "        errD_real = self.criterion(output, label)\n",
    "        self.manual_backward(errD_real)\n",
    "        #errD_real.backward()\n",
    "        \n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        label.fill_(self.fake_label)\n",
    "        fake_images = self(noise).detach() # Отключаем градиенты для фейковых изображений\n",
    "        output = self.discriminator(fake_images).view(-1)\n",
    "        errD_fake = self.criterion(output, label)\n",
    "        #errD_fake.backward()\n",
    "        self.manual_backward(errD_fake)\n",
    "        opt_d.step()\n",
    "\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        if batch_idx % 2 == 0:\n",
    "            self.log('errD', errD.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('errG', errG.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('D_x', D_x, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('D_G_z1', D_G_z1, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('D_G_z2', D_G_z2, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "            \n",
    "            # task.get_logger().report_scalar(\"errD\", \"value\", iteration=self.global_step, value=errD.item())\n",
    "            # task.get_logger().report_scalar(\"errG\", \"value\", iteration=self.global_step, value=errG.item())\n",
    "        \n",
    "        #return errD \n",
    "        \n",
    "    # def on_train_epoch_start(self):\n",
    "        # self.current_epoch += 1\n",
    "            \n",
    "    def on_train_epoch_end(self):\n",
    "        if self.current_epoch % 2 == 0:\n",
    "            fixed_noise = torch.randn(64, self.noise_dim, device=device)\n",
    "            fake_images = self(fixed_noise).detach().cpu()\n",
    "            os.makedirs('output', exist_ok=True)\n",
    "            torchvision.utils.save_image(fake_images, f'output/fake_images_epoch_{self.current_epoch}.png', normalize=True)\n",
    "            # task.get_logger().report_image(\n",
    "            #     \"fake_images\",\n",
    "            #     iteration=self.current_epoch,\n",
    "            #     series=\"GAN\",\n",
    "            #     local_path=f'output/fake_images_epoch_{self.current_epoch}.png'\n",
    "            # )\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_g = optim.Adam(self.generator.parameters(), lr=cfg.lr, betas=(0.5, 0.999))\n",
    "        optimizer_d = optim.Adam(self.discriminator.parameters(), lr=cfg.lr, betas=(0.5, 0.999))\n",
    "        return [optimizer_g, optimizer_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4fe0464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.2\n",
      "2.5.1+cu121\n",
      "_CudaDeviceProperties(name='NVIDIA GeForce RTX 4080', major=8, minor=9, total_memory=15921MB, multi_processor_count=76, uuid=f9834d31-4bef-eede-d0e5-7030f23b7e14, L2_cache_size=64MB)\n"
     ]
    }
   ],
   "source": [
    "import lightning\n",
    "print(lightning.__version__)\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.get_device_properties(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "860133e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | generator     | Generator     | 1.8 M  | train\n",
      "1 | discriminator | Discriminator | 138 K  | train\n",
      "2 | criterion     | BCELoss       | 0      | train\n",
      "--------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.729     Total estimated model params size (MB)\n",
      "21        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a06c40998e64d51845c01caae2ea7a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "data = MNISTDataModule(batch_size=cfg.batch_size)\n",
    "model = GAN_MNIST_Model(gen_dict=cfg.gen_dict, disc_dict=cfg.disc_dict, noise_dim=cfg.noise_dim)\n",
    "trainer = Trainer(\n",
    "    accelerator='auto',\n",
    "    devices=-1,\n",
    "    max_epochs=1,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            monitor='D_G_z2',\n",
    "            mode='min',\n",
    "            save_top_k=1,\n",
    "            save_weights_only=True,\n",
    "            dirpath='models',\n",
    "            filename='generator',\n",
    "            enable_version_counter=True,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ce54f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "linalg.eig(A, *, out=None) -> (Tensor, Tensor)\n",
      "\n",
      "Computes the eigenvalue decomposition of a square matrix if it exists.\n",
      "\n",
      "Letting :math:`\\mathbb{K}` be :math:`\\mathbb{R}` or :math:`\\mathbb{C}`,\n",
      "the **eigenvalue decomposition** of a square matrix\n",
      ":math:`A \\in \\mathbb{K}^{n \\times n}` (if it exists) is defined as\n",
      "\n",
      ".. math::\n",
      "\n",
      "    A = V \\operatorname{diag}(\\Lambda) V^{-1}\\mathrlap{\\qquad V \\in \\mathbb{C}^{n \\times n}, \\Lambda \\in \\mathbb{C}^n}\n",
      "\n",
      "This decomposition exists if and only if :math:`A` is `diagonalizable`_.\n",
      "This is the case when all its eigenvalues are different.\n",
      "\n",
      "Supports input of float, double, cfloat and cdouble dtypes.\n",
      "Also supports batches of matrices, and if :attr:`A` is a batch of matrices then\n",
      "the output has the same batch dimensions.\n",
      "\n",
      ".. note:: The eigenvalues and eigenvectors of a real matrix may be complex.\n",
      "\n",
      "\n",
      ".. note:: When inputs are on a CUDA device, this function synchronizes that device with the CPU.\n",
      "\n",
      "\n",
      ".. warning:: This function assumes that :attr:`A` is `diagonalizable`_ (for example, when all the\n",
      "             eigenvalues are different). If it is not diagonalizable, the returned\n",
      "             eigenvalues will be correct but :math:`A \\neq V \\operatorname{diag}(\\Lambda)V^{-1}`.\n",
      "\n",
      ".. warning:: The returned eigenvectors are normalized to have norm `1`.\n",
      "             Even then, the eigenvectors of a matrix are not unique, nor are they continuous with respect to\n",
      "             :attr:`A`. Due to this lack of uniqueness, different hardware and software may compute\n",
      "             different eigenvectors.\n",
      "\n",
      "             This non-uniqueness is caused by the fact that multiplying an eigenvector by\n",
      "             by :math:`e^{i \\phi}, \\phi \\in \\mathbb{R}` produces another set of valid eigenvectors\n",
      "             of the matrix.  For this reason, the loss function shall not depend on the phase of the\n",
      "             eigenvectors, as this quantity is not well-defined.\n",
      "             This is checked when computing the gradients of this function. As such,\n",
      "             when inputs are on a CUDA device, the computation of the gradients\n",
      "             of this function synchronizes that device with the CPU.\n",
      "\n",
      "\n",
      ".. warning:: Gradients computed using the `eigenvectors` tensor will only be finite when\n",
      "             :attr:`A` has distinct eigenvalues.\n",
      "             Furthermore, if the distance between any two eigenvalues is close to zero,\n",
      "             the gradient will be numerically unstable, as it depends on the eigenvalues\n",
      "             :math:`\\lambda_i` through the computation of\n",
      "             :math:`\\frac{1}{\\min_{i \\neq j} \\lambda_i - \\lambda_j}`.\n",
      "\n",
      ".. seealso::\n",
      "\n",
      "        :func:`torch.linalg.eigvals` computes only the eigenvalues.\n",
      "        Unlike :func:`torch.linalg.eig`, the gradients of :func:`~eigvals` are always\n",
      "        numerically stable.\n",
      "\n",
      "        :func:`torch.linalg.eigh` for a (faster) function that computes the eigenvalue decomposition\n",
      "        for Hermitian and symmetric matrices.\n",
      "\n",
      "        :func:`torch.linalg.svd` for a function that computes another type of spectral\n",
      "        decomposition that works on matrices of any shape.\n",
      "\n",
      "        :func:`torch.linalg.qr` for another (much faster) decomposition that works on matrices of\n",
      "        any shape.\n",
      "\n",
      "Args:\n",
      "    A (Tensor): tensor of shape `(*, n, n)` where `*` is zero or more batch dimensions\n",
      "                consisting of diagonalizable matrices.\n",
      "\n",
      "Keyword args:\n",
      "    out (tuple, optional): output tuple of two tensors. Ignored if `None`. Default: `None`.\n",
      "\n",
      "Returns:\n",
      "    A named tuple `(eigenvalues, eigenvectors)` which corresponds to :math:`\\Lambda` and :math:`V` above.\n",
      "\n",
      "    `eigenvalues` and `eigenvectors` will always be complex-valued, even when :attr:`A` is real. The eigenvectors\n",
      "    will be given by the columns of `eigenvectors`.\n",
      "\n",
      "Examples::\n",
      "\n",
      "    >>> A = torch.randn(2, 2, dtype=torch.complex128)\n",
      "    >>> A\n",
      "    tensor([[ 0.9828+0.3889j, -0.4617+0.3010j],\n",
      "            [ 0.1662-0.7435j, -0.6139+0.0562j]], dtype=torch.complex128)\n",
      "    >>> L, V = torch.linalg.eig(A)\n",
      "    >>> L\n",
      "    tensor([ 1.1226+0.5738j, -0.7537-0.1286j], dtype=torch.complex128)\n",
      "    >>> V\n",
      "    tensor([[ 0.9218+0.0000j,  0.1882-0.2220j],\n",
      "            [-0.0270-0.3867j,  0.9567+0.0000j]], dtype=torch.complex128)\n",
      "    >>> torch.dist(V @ torch.diag(L) @ torch.linalg.inv(V), A)\n",
      "    tensor(7.7119e-16, dtype=torch.float64)\n",
      "\n",
      "    >>> A = torch.randn(3, 2, 2, dtype=torch.float64)\n",
      "    >>> L, V = torch.linalg.eig(A)\n",
      "    >>> torch.dist(V @ torch.diag_embed(L) @ torch.linalg.inv(V), A)\n",
      "    tensor(3.2841e-16, dtype=torch.float64)\n",
      "\n",
      ".. _diagonalizable:\n",
      "    https://en.wikipedia.org/wiki/Diagonalizable_matrix#Definition\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "torch.nn.functional"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
