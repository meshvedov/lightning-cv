{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850a397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from lightning import Trainer, LightningModule, LightningDataModule\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, RichProgressBar\n",
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from clearml import Task\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cf2e0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 42, 'batch_size': 64, 'lr': 0.0002, 'num_epochs': 10, 'noise_dim': 100, 'device': 'cuda', 'gen_dict': {'kernel_size': 4, 'stride': 2, 'padding': 1}, 'disc_dict': {'kernel_size': 4, 'stride': 2, 'padding': 1}}\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class CFG:\n",
    "    seed: int = 42\n",
    "    batch_size: int = 64\n",
    "    lr: float = 0.0002\n",
    "    num_epochs: int = 10\n",
    "    noise_dim: int = 100\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    gen_dict: dict = field(default_factory=lambda: {\n",
    "        'kernel_size': 4,\n",
    "        'stride': 2,\n",
    "        'padding': 1,\n",
    "    })\n",
    "    disc_dict: dict = field(default_factory=lambda: {\n",
    "        'kernel_size': 4,\n",
    "        'stride': 2,\n",
    "        'padding': 1,\n",
    "    })\n",
    "    \n",
    "cfg = CFG()\n",
    "cfg_dict = asdict(cfg)\n",
    "print(cfg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ebe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task.init(project_name='GAN', task_name='GAN Training', task_type=Task.TaskTypes.training)\n",
    "#task.add_tags([])\n",
    "task.connect(cfg_dict) # Добавление конфигурации в ClearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "072eeb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(LightningDataModule):\n",
    "    def __init__(self, batch_size=64):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        datasets.MNIST(root='./data', train=True, download=True)\n",
    "        datasets.MNIST(root='./data', train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.mnist_train = datasets.MNIST(root='./data', train=True, transform=self.transform)\n",
    "        self.mnist_test = datasets.MNIST(root='./data', train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size, shuffle=True, num_workers=20)\n",
    "\n",
    "    # def val_dataloader(self):\n",
    "    #     return DataLoader(self.mnist_test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbbb76f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:05<00:00, 1839893.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 151400.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1047197.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 5372399.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "module = MNISTDataModule(batch_size=batch_size)\n",
    "module.prepare_data()\n",
    "module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "934dd62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(LightningModule):\n",
    "    def __init__(self, noise_dim=100, *args, **kwargs):\n",
    "        super(Generator, self).__init__()\n",
    "        kernel_size = kwargs.get('kernel_size', 4)\n",
    "        stride = kwargs.get('stride', 2)\n",
    "        padding = kwargs.get('padding', 1)\n",
    "        self.main = nn.Sequential(\n",
    "            # Вход: вектор шума размера noise_dim\n",
    "            nn.Linear(noise_dim, 256 * 7 * 7),\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(1, (256, 7, 7)),\n",
    "            # Состояние: (256, 7, 7)\n",
    "            nn.ConvTranspose2d(\n",
    "                256, 128, kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n",
    "            ),  # -> (128, 14, 14)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(\n",
    "                128, 1, kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n",
    "            ),  # -> (1, 28, 28)\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "        \n",
    "        \n",
    "class Discriminator(LightningModule):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Discriminator, self).__init__()\n",
    "        kernel_size = kwargs.get('kernel_size', 4)\n",
    "        stride = kwargs.get('stride', 2)\n",
    "        padding = kwargs.get('padding', 1)\n",
    "        self.main = nn.Sequential(\n",
    "            # Вход: изображение (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                1, 64, kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n",
    "            ),  # -> (64, 14, 14)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(\n",
    "                64, 128, kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n",
    "            ),  # -> (128, 7, 7)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 7 * 7, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11a50fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_MNIST_Model(LightningModule):\n",
    "    def __init__(self, noise_dim=100, gen_dict=None, disc_dict=None):\n",
    "        super().__init__()\n",
    "        self.generator = Generator(noise_dim=noise_dim, **(gen_dict or {})).to(self.device)\n",
    "        self.discriminator = Discriminator( **(disc_dict or {})).to(self.device)\n",
    "        self.criterion = nn.BCELoss()\n",
    "        \n",
    "        self.noise_dim = noise_dim\n",
    "        self.real_label = 1.0\n",
    "        self.fake_label = 0.0\n",
    "        self.automatic_optimization = False  # Отключаем автоматическое управление оптимизацией\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.generator(input)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # import pdb; pdb.set_trace()\n",
    "        opt_g, opt_d = self.optimizers()\n",
    "        real_images, _ = batch\n",
    "        batch_size = real_images.size(0)\n",
    "        noise = torch.randn(batch_size, self.noise_dim, device=self.device)\n",
    "        label = torch.full((batch_size,), self.real_label, device=self.device)\n",
    "\n",
    "        # Обучение генератора\n",
    "        opt_g.zero_grad()\n",
    "        fake_images = self(noise)\n",
    "        output = self.discriminator(fake_images).view(-1)\n",
    "        errG = self.criterion(output, label)\n",
    "        D_G_z2 = output.mean().item()\n",
    "        #errG.backward()\n",
    "        self.manual_backward(errG)\n",
    "        opt_g.step()\n",
    "        #optimizer_g.step()\n",
    "        #return errG\n",
    "\n",
    "        # Обучение дискриминатора\n",
    "        opt_d.zero_grad()\n",
    "        output = self.discriminator(real_images).view(-1)\n",
    "        errD_real = self.criterion(output, label)\n",
    "        self.manual_backward(errD_real)\n",
    "        #errD_real.backward()\n",
    "        \n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        label.fill_(self.fake_label)\n",
    "        fake_images = self(noise).detach() # Отключаем градиенты для фейковых изображений\n",
    "        output = self.discriminator(fake_images).view(-1)\n",
    "        errD_fake = self.criterion(output, label)\n",
    "        #errD_fake.backward()\n",
    "        self.manual_backward(errD_fake)\n",
    "        opt_d.step()\n",
    "\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        if batch_idx % 2 == 0:\n",
    "            self.log('errD', errD.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('errG', errG.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('D_x', D_x, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('D_G_z1', D_G_z1, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('D_G_z2', D_G_z2, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "            \n",
    "            # task.get_logger().report_scalar(\"errD\", \"value\", iteration=self.global_step, value=errD.item())\n",
    "            # task.get_logger().report_scalar(\"errG\", \"value\", iteration=self.global_step, value=errG.item())\n",
    "        \n",
    "        #return errD \n",
    "        \n",
    "    # def on_train_epoch_start(self):\n",
    "        # self.current_epoch += 1\n",
    "            \n",
    "    def on_train_epoch_end(self):\n",
    "        if self.current_epoch % 2 == 0:\n",
    "            fixed_noise = torch.randn(64, self.noise_dim, device=self.device)\n",
    "            fake_images = self(fixed_noise).detach().cpu()\n",
    "            os.makedirs('output', exist_ok=True)\n",
    "            torchvision.utils.save_image(fake_images, f'output/fake_images_epoch_{self.current_epoch}.png', normalize=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_g = optim.Adam(self.generator.parameters(), lr=cfg.lr, betas=(0.5, 0.999))\n",
    "        optimizer_d = optim.Adam(self.discriminator.parameters(), lr=cfg.lr, betas=(0.5, 0.999))\n",
    "        return [optimizer_g, optimizer_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "860133e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ generator     │ Generator     │  1.8 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ discriminator │ Discriminator │  138 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ criterion     │ BCELoss       │      0 │ train │\n",
       "└───┴───────────────┴───────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ generator     │ Generator     │  1.8 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ discriminator │ Discriminator │  138 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ criterion     │ BCELoss       │      0 │ train │\n",
       "└───┴───────────────┴───────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 1.9 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 1.9 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 7                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 21                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 1.9 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 1.9 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 7                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 21                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269977c2fd9e43a6a87d696ce1cb00f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b2ee8915c24437a3ecee1c27bdd46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f121133baff24743b10e8543d7c438ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623bdc9aa926456bb55db88fe8f499a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7a23901b0944f386e6ffd0f2a3be5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845dc45f6b534dd9a9307cf897113c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458fdefe7bf3415ca553f5036bea43b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24108a1603c44f10997e4fff1d2ac2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb22a79093a34642b4683abb67ae0847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3e534d447945328df94ae03be2e3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = MNISTDataModule(batch_size=cfg.batch_size)\n",
    "model = GAN_MNIST_Model(gen_dict=cfg.gen_dict, disc_dict=cfg.disc_dict, noise_dim=cfg.noise_dim)\n",
    "trainer = Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=1,\n",
    "    max_epochs=10,\n",
    "    callbacks=[\n",
    "        RichProgressBar(leave=True),\n",
    "        ModelCheckpoint(\n",
    "            monitor='D_G_z2',\n",
    "            mode='min',\n",
    "            save_top_k=1,\n",
    "            save_weights_only=True,\n",
    "            dirpath='models',\n",
    "            filename='generator',\n",
    "            enable_version_counter=True,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "trainer.fit(model, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
