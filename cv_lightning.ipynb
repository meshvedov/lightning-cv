{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "850a397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from lightning import Trainer, LightningModule, LightningDataModule\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, RichProgressBar\n",
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from clearml import Task\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "116106e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cu121'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cf2e0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 42, 'batch_size': 64, 'lr': 0.0002, 'num_epochs': 10, 'noise_dim': 100, 'gen_dict': {'kernel_size': 4, 'stride': 2, 'padding': 1}, 'disc_dict': {'kernel_size': 4, 'stride': 2, 'padding': 1}}\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class CFG:\n",
    "    seed: int = 42\n",
    "    batch_size: int = 64\n",
    "    lr: float = 0.0002\n",
    "    num_epochs: int = 10\n",
    "    noise_dim: int = 100\n",
    "    # device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    gen_dict: dict = field(default_factory=lambda: {\n",
    "        'kernel_size': 4,\n",
    "        'stride': 2,\n",
    "        'padding': 1,\n",
    "    })\n",
    "    disc_dict: dict = field(default_factory=lambda: {\n",
    "        'kernel_size': 4,\n",
    "        'stride': 2,\n",
    "        'padding': 1,\n",
    "    })\n",
    "    \n",
    "cfg = CFG()\n",
    "cfg_dict = asdict(cfg)\n",
    "print(cfg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55b0e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f70ebe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = Task.init(project_name='GAN', task_name='GAN Training', task_type=Task.TaskTypes.training)\n",
    "# #task.add_tags([])\n",
    "# task.connect(cfg_dict) # Добавление конфигурации в ClearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "072eeb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(LightningDataModule):\n",
    "    def __init__(self, batch_size=64):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        datasets.MNIST(root='./data', train=True, download=True)\n",
    "        datasets.MNIST(root='./data', train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.mnist_train = datasets.MNIST(root='./data', train=True, transform=self.transform)\n",
    "        self.mnist_test = datasets.MNIST(root='./data', train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size, shuffle=True, num_workers=20)\n",
    "\n",
    "    # def val_dataloader(self):\n",
    "    #     return DataLoader(self.mnist_test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbbb76f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = MNISTDataModule(batch_size=cfg.batch_size)\n",
    "module.prepare_data()\n",
    "module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "934dd62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim=100, *args, **kwargs):\n",
    "        super(Generator, self).__init__()\n",
    "        kernel_size = kwargs.get('kernel_size', 4)\n",
    "        stride = kwargs.get('stride', 2)\n",
    "        padding = kwargs.get('padding', 1)\n",
    "        self.main = nn.Sequential(\n",
    "            # Вход: вектор шума размера noise_dim\n",
    "            nn.Linear(noise_dim, 256 * 7 * 7),\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(1, (256, 7, 7)),\n",
    "            # Состояние: (256, 7, 7)\n",
    "            nn.ConvTranspose2d(\n",
    "                256, 128, kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n",
    "            ),  # -> (128, 14, 14)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(\n",
    "                128, 1, kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n",
    "            ),  # -> (1, 28, 28)\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "        \n",
    "        \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Discriminator, self).__init__()\n",
    "        kernel_size = kwargs.get('kernel_size', 4)\n",
    "        stride = kwargs.get('stride', 2)\n",
    "        padding = kwargs.get('padding', 1)\n",
    "        self.main = nn.Sequential(\n",
    "            # Вход: изображение (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                1, 64, kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n",
    "            ),  # -> (64, 14, 14)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(\n",
    "                64, 128, kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n",
    "            ),  # -> (128, 7, 7)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 7 * 7, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11a50fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_MNIST_Model(LightningModule):\n",
    "    def __init__(self, noise_dim=100, gen_dict=None, disc_dict=None):\n",
    "        super().__init__()\n",
    "        self.generator = Generator(noise_dim=noise_dim, **(gen_dict or {})).to(device)\n",
    "        self.discriminator = Discriminator( **(disc_dict or {})).to(device)\n",
    "        self.criterion = nn.BCELoss()\n",
    "        \n",
    "        self.noise_dim = noise_dim\n",
    "        self.real_label = 1.0\n",
    "        self.fake_label = 0.0\n",
    "        self.automatic_optimization = False  # Отключаем автоматическое управление оптимизацией\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.generator(input)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # import pdb; pdb.set_trace()\n",
    "        opt_g, opt_d = self.optimizers()\n",
    "        real_images, _ = batch\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "        noise = torch.randn(batch_size, self.noise_dim, device=device)\n",
    "        label = torch.full((batch_size,), self.real_label, device=device)\n",
    "\n",
    "        # Обучение генератора\n",
    "        opt_g.zero_grad()\n",
    "        fake_images = self(noise)\n",
    "        output = self.discriminator(fake_images).view(-1)\n",
    "        errG = self.criterion(output, label)\n",
    "        D_G_z2 = output.mean().item()\n",
    "        #errG.backward()\n",
    "        self.manual_backward(errG)\n",
    "        opt_g.step()\n",
    "        #optimizer_g.step()\n",
    "        #return errG\n",
    "\n",
    "        # Обучение дискриминатора\n",
    "        opt_d.zero_grad()\n",
    "        output = self.discriminator(real_images).view(-1)\n",
    "        errD_real = self.criterion(output, label)\n",
    "        self.manual_backward(errD_real)\n",
    "        #errD_real.backward()\n",
    "        \n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        label.fill_(self.fake_label)\n",
    "        fake_images = self(noise).detach() # Отключаем градиенты для фейковых изображений\n",
    "        output = self.discriminator(fake_images).view(-1)\n",
    "        errD_fake = self.criterion(output, label)\n",
    "        #errD_fake.backward()\n",
    "        self.manual_backward(errD_fake)\n",
    "        opt_d.step()\n",
    "\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        if batch_idx % 2 == 0:\n",
    "            self.log('errD', errD.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('errG', errG.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('D_x', D_x, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('D_G_z1', D_G_z1, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('D_G_z2', D_G_z2, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "            \n",
    "            # task.get_logger().report_scalar(\"errD\", \"value\", iteration=self.global_step, value=errD.item())\n",
    "            # task.get_logger().report_scalar(\"errG\", \"value\", iteration=self.global_step, value=errG.item())\n",
    "        \n",
    "        #return errD \n",
    "        \n",
    "    # def on_train_epoch_start(self):\n",
    "        # self.current_epoch += 1\n",
    "            \n",
    "    def on_train_epoch_end(self):\n",
    "        if self.current_epoch % 2 == 0:\n",
    "            fixed_noise = torch.randn(64, self.noise_dim, device=device)\n",
    "            fake_images = self(fixed_noise).detach().cpu()\n",
    "            os.makedirs('output', exist_ok=True)\n",
    "            torchvision.utils.save_image(fake_images, f'output/fake_images_epoch_{self.current_epoch}.png', normalize=True)\n",
    "            # task.get_logger().report_image(\n",
    "            #     \"fake_images\",\n",
    "            #     iteration=self.current_epoch,\n",
    "            #     series=\"GAN\",\n",
    "            #     local_path=f'output/fake_images_epoch_{self.current_epoch}.png'\n",
    "            # )\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_g = optim.Adam(self.generator.parameters(), lr=cfg.lr, betas=(0.5, 0.999))\n",
    "        optimizer_d = optim.Adam(self.discriminator.parameters(), lr=cfg.lr, betas=(0.5, 0.999))\n",
    "        return [optimizer_g, optimizer_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4fe0464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.2\n",
      "2.5.1+cu121\n",
      "_CudaDeviceProperties(name='NVIDIA GeForce RTX 4080', major=8, minor=9, total_memory=15921MB, multi_processor_count=76, uuid=f9834d31-4bef-eede-d0e5-7030f23b7e14, L2_cache_size=64MB)\n"
     ]
    }
   ],
   "source": [
    "import lightning\n",
    "print(lightning.__version__)\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.get_device_properties(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "860133e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | generator     | Generator     | 1.8 M  | train\n",
      "1 | discriminator | Discriminator | 138 K  | train\n",
      "2 | criterion     | BCELoss       | 0      | train\n",
      "--------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.729     Total estimated model params size (MB)\n",
      "21        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a06c40998e64d51845c01caae2ea7a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "data = MNISTDataModule(batch_size=cfg.batch_size)\n",
    "model = GAN_MNIST_Model(gen_dict=cfg.gen_dict, disc_dict=cfg.disc_dict, noise_dim=cfg.noise_dim)\n",
    "trainer = Trainer(\n",
    "    accelerator='auto',\n",
    "    devices=-1,\n",
    "    max_epochs=1,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            monitor='D_G_z2',\n",
    "            mode='min',\n",
    "            save_top_k=1,\n",
    "            save_weights_only=True,\n",
    "            dirpath='models',\n",
    "            filename='generator',\n",
    "            enable_version_counter=True,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "trainer.fit(model, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
